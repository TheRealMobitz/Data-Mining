{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Assignment 1\n",
    "\n",
    "This notebook contains the steps for completing Data Mining Assignment 1, including initial data analysis, preprocessing, and a summary of findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the Dataset\n",
    "We start by loading the dataset and examining its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('superstore.csv')\n",
    "\n",
    "# Examine structure\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Descriptive Statistics\n",
    "Next, we extract descriptive statistics for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Identify Missing Values\n",
    "We check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Quality Assessment\n",
    "We assess data quality by checking for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDuplicate Rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Data Visualization\n",
    "We create various visualizations to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "df.hist(figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig('initial_histograms.png')\n",
    "plt.show()\n",
    "\n",
    "# Box plots for numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.savefig(f'initial_boxplot_{col}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Pairwise scatter plots\n",
    "sns.pairplot(df[numerical_cols])\n",
    "plt.savefig('initial_pairplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Checklist of Issues\n",
    "We create a checklist of identified issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = {\n",
    "    \"Missing Values\": missing_values[missing_values > 0].index.tolist(),\n",
    "    \"Outliers\": [col for col in numerical_cols if df[col].skew().abs() > 1 or len(df[col].dropna()) - len(df[col].dropna().between(df[col].quantile(0.25) - 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25)), df[col].quantile(0.75) + 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25)))) > 0],\n",
    "    \"Duplicates\": df.duplicated().sum() > 0\n",
    "}\n",
    "print(\"\\nChecklist of Issues:\", issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Handle Missing Values\n",
    "We handle missing values using mean imputation for numerical columns and forward fill for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean imputation for numerical columns\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Forward fill for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remove Outliers\n",
    "We remove outliers using the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[~((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Correct Inconsistent Data\n",
    "We correct inconsistent data, such as standardizing country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = df['Country'].str.strip().replace({'United Stateshcr': 'United States', 'United Kingdomegb': 'United Kingdom'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Standardization/Normalization\n",
    "We create standardized and normalized versions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Normalization\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_normalized = df.copy()\n",
    "df_normalized[numerical_cols] = minmax_scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Remove Duplicates\n",
    "We remove duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Compare Distributions\n",
    "We compare the distributions of two features using KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sales vs Profit\n",
    "kl_div_sales_profit = entropy(df['Sales'].dropna(), df['Profit'].dropna())\n",
    "print(\"\\nKL Divergence (Sales vs Profit):\", kl_div_sales_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Visualize Cleaned Data\n",
    "We create visualizations for the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.hist(figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig('cleaned_histograms.png')\n",
    "plt.show()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=df_normalized[col])\n",
    "    plt.title(f'Cleaned Box Plot of {col}')\n",
    "    plt.savefig(f'cleaned_boxplot_{col}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Improvement Statistics\n",
    "We compare the number of missing values and duplicates before and after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_missing = missing_values.sum()\n",
    "cleaned_missing = df.isnull().sum().sum()\n",
    "print(\"\\nMissing Values Before:\", initial_missing)\n",
    "print(\"Missing Values After:\", cleaned_missing)\n",
    "print(\"Duplicates Removed:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Dependencies\n",
    "We create a correlation matrix to evaluate feature dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df[numerical_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Comprehensive Report\n",
    "Below is a summary of the steps performed and the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Assignment 1 Report\n",
    "\n",
    "## 1. Initial Data Analysis\n",
    "- **Shape**: (number of rows, number of columns)\n",
    "- **Missing Values**: Total missing values across columns\n",
    "- **Outliers**: Detected in specific columns\n",
    "- **Duplicates**: Number of duplicate rows\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "- **Missing Values**: Handled using mean imputation and forward fill.\n",
    "- **Outliers**: Removed using IQR method.\n",
    "- **Inconsistent Data**: Standardized 'Country' column.\n",
    "- **Normalization**: Applied MinMax scaling.\n",
    "- **Duplicates**: Removed duplicate rows.\n",
    "- **KL Divergence**: Calculated for Sales vs Profit.\n",
    "\n",
    "## 3. Results\n",
    "- **Missing Values Reduced**: From initial to final count.\n",
    "- **Visualizations**: See 'initial_' and 'cleaned_' PNG files.\n",
    "- **Feature Dependencies**: Correlation matrix saved as 'correlation_matrix.png'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
